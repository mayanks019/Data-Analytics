{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464084d3-edd5-4b1f-929e-8eb032d18cb4",
   "metadata": {},
   "source": [
    "## Supervised Learning: Regression Models and Performance Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7c81c-eb1f-41d2-8831-f9fd00f4e921",
   "metadata": {},
   "source": [
    "1. What is Simple Linear Regression (SLR)? Explain its purpose.\n",
    "\n",
    "    Simple Linear Regression (SLR) is a statistical technique used to model the relationship between two variables â€” one independent variable (predictor) and one dependent variable (response) â€” by fitting a straight line through the data points.\n",
    "    \n",
    "    The main goal of SLR is to understand and predict how changes in the independent variable influence the dependent variable. The line of best fit helps to summarize the overall pattern in the data.\n",
    "    \n",
    "    Purpose of Simple Linear Regression:\n",
    "    \n",
    "    Prediction: To predict the value of the dependent variable (Y) for a given value of the independent variable (X).\n",
    "    \n",
    "    Relationship Understanding: To determine whether there is a significant linear relationship between X and Y.\n",
    "    \n",
    "    Trend Analysis: To identify trends and make future forecasts.\n",
    "    \n",
    "    Quantifying Effect: To measure how much Y changes for a one-unit change in X.\n",
    "    \n",
    "    In summary, SLR provides a simple yet powerful way to explore relationships and make data-driven decisions in business, science, and engineering.\n",
    "\n",
    "2. What are the key assumptions of Simple Linear Regression?\n",
    "\n",
    "\n",
    "    For a simple linear regression model to produce valid and reliable results, several key assumptions must be met. Violating these assumptions can lead to biased estimates or incorrect conclusions.\n",
    "    \n",
    "    Linearity:\n",
    "    The relationship between the independent variable (X) and dependent variable (Y) must be linear. The model assumes that the change in Y is proportional to the change in X.\n",
    "    \n",
    "    Independence of Errors:\n",
    "    The residuals (errors) should be independent of each other. In time-series data, this means there should be no autocorrelation.\n",
    "    \n",
    "    Homoscedasticity:\n",
    "    The variance of residuals should be constant across all levels of X. If the spread of residuals increases or decreases, it indicates heteroscedasticity.\n",
    "    \n",
    "    Normality of Errors:\n",
    "    The residuals should be approximately normally distributed, especially for small sample sizes. This ensures accurate hypothesis testing.\n",
    "    \n",
    "    No Perfect Multicollinearity:\n",
    "    In simple regression, this assumption naturally holds because there is only one predictor variable.\n",
    "    \n",
    "    When all these assumptions are satisfied, the modelâ€™s predictions and statistical tests (like p-values and confidence intervals) are considered reliable.\n",
    "\n",
    "3. Write the mathematical equation for a simple linear regression model and explain each term.\n",
    "\n",
    "    The general equation for Simple Linear Regression is:\n",
    "    \n",
    "    ğ‘Œ =ğ›½0+ğ›½1ğ‘‹+ğœ–\n",
    "    \n",
    "    Where:\n",
    "    Y: Dependent variable (the variable we want to predict).\n",
    "    X: Independent variable (the variable used for prediction).\n",
    "    ğ›½0: Intercept term; the predicted value of Y when X = 0.\n",
    "    Î²1: Slope coefficient; represents how much Y changes for a one-unit increase in X.\n",
    "    Ïµ: Error term; represents random variation or factors not captured by the model.\n",
    "    \n",
    "    This equation defines a straight line where the parameters Î²0 and Î²1 are estimated using the method of least squares.\n",
    "\n",
    "4. Provide a real-world example where simple linear regression can be applied.\n",
    "\n",
    "    A practical example of Simple Linear Regression is predicting house prices based on their size (in square feet).\n",
    "    \n",
    "    In this scenario:\n",
    "    \n",
    "    Dependent variable (Y): House price (in â‚¹ or $).\n",
    "    \n",
    "    Independent variable (X): Size of the house (square feet).\n",
    "    \n",
    "    Using SLR, we can model the relationship as:\n",
    "    \n",
    "    Price =ğ›½0+ğ›½1Ã—(Size)+ ğœ–\n",
    "    \n",
    "    If we find that ğ›½1=2500 it means for every additional square foot, the house price increases by â‚¹2500 on average.\n",
    "    \n",
    "    Other real-world examples include:\n",
    "    \n",
    "    Predicting sales based on advertising budget.\n",
    "    \n",
    "    Estimating student performance based on study hours.\n",
    "    \n",
    "    Forecasting electricity consumption based on temperature.\n",
    "    \n",
    "    These applications help businesses and researchers make informed predictions and strategic decisions.\n",
    "\n",
    "5. What is the method of least squares in linear regression?\n",
    "\n",
    "    \n",
    "    The method of least squares is a mathematical approach used to determine the best-fitting line through a set of data points in linear regression. It minimizes the sum of the squared differences (errors) between the observed values and the predicted values from the model.\n",
    "    \n",
    "    Formally, we minimize the following function:\n",
    "    \n",
    "    Minimize\n",
    "    â€…â€Šâˆ‘(ğ‘Œğ‘–âˆ’ğ‘Œğ‘–^)2\n",
    "    \n",
    "    where \n",
    "    \n",
    "    Yi is the actual value, and \n",
    "    ğ‘Œğ‘–^ is the predicted value from the model.\n",
    "    \n",
    "    By minimizing this sum, we find the values of \n",
    "    \n",
    "    Î²0 (intercept) and \n",
    "    \n",
    "    Î²1 (slope) that make the line fit the data as closely as possible.\n",
    "    \n",
    "    Advantages:\n",
    "    \n",
    "    Provides the most accurate line of fit under the assumption of normally distributed errors.\n",
    "    \n",
    "    Ensures unbiased and efficient parameter estimates.\n",
    "\n",
    "6. What is Logistic Regression? How does it differ from Linear Regression?\n",
    "\n",
    "    Logistic Regression is a statistical technique used for classification problems, where the dependent variable is categorical (e.g., yes/no, 0/1, true/false). It predicts the probability of an event occurring rather than predicting continuous values.\n",
    "    \n",
    "    In contrast, Linear Regression predicts continuous numeric outcomes (like sales, income, or height).\n",
    "    \n",
    "    Key Differences:\n",
    "    \n",
    "    Nature of Output:\n",
    "    Linear regression predicts continuous values, while logistic regression predicts probabilities between 0 and 1.\n",
    "    \n",
    "    Model Equation:\n",
    "    Logistic regression uses the logit (sigmoid) function to map predictions between 0 and 1:\n",
    "    \n",
    "    ğ‘ƒ(ğ‘Œ=1)=11+ğ‘’âˆ’(ğ›½0+ğ›½1ğ‘‹)\n",
    "    \n",
    "    Error Type:\n",
    "    Linear regression uses least squares; logistic regression uses likelihood estimation.\n",
    "    \n",
    "    Purpose:\n",
    "    Linear â†’ regression problems, Logistic â†’ classification problems.\n",
    "\n",
    "7. Name and briefly describe three common evaluation metrics for regression models.\n",
    "\n",
    "\n",
    "    Three widely used regression evaluation metrics are:\n",
    "    \n",
    "    Mean Absolute Error (MAE):\n",
    "    Measures the average magnitude of errors between predicted and actual values.\n",
    "    \n",
    "    ğ‘€ğ´ğ¸=1ğ‘›âˆ‘âˆ£ğ‘Œğ‘–âˆ’ğ‘Œğ‘–^âˆ£\n",
    "    \n",
    "    \n",
    "    It is simple and interpretable in the same units as the data.\n",
    "    \n",
    "    Mean Squared Error (MSE):\n",
    "    Measures the average of the squared differences between actual and predicted values.\n",
    "    \n",
    "    ğ‘€ğ‘†ğ¸=1ğ‘›âˆ‘(ğ‘Œğ‘–âˆ’ğ‘Œğ‘–^)2\n",
    "    \n",
    "    \n",
    "    It penalizes large errors more than small ones.\n",
    "    \n",
    "    Root Mean Squared Error (RMSE):\n",
    "    Square root of MSE; it gives errors in the same units as the target variable.\n",
    "    Lower RMSE indicates a better model.\n",
    "    \n",
    "    These metrics help compare different models and evaluate their prediction accuracy.\n",
    "\n",
    "8. What is the purpose of the R-squared metric in regression analysis?\n",
    "\n",
    "    R-squared (Coefficient of Determination) measures how well the regression model explains the variability of the dependent variable. It is defined as:\n",
    "    \n",
    "    ğ‘…2=1âˆ’ğ‘†ğ‘†ğ‘Ÿğ‘’ğ‘  / ğ‘†ğ‘†ğ‘¡ğ‘œğ‘¡\n",
    "    \n",
    "    \n",
    "    Where:\n",
    "    \n",
    "    ğ‘†ğ‘†ğ‘Ÿğ‘’ğ‘ : Sum of squared residuals.\n",
    "    \n",
    "    ğ‘†ğ‘†ğ‘¡ğ‘œğ‘¡: Total sum of squares (variation in Y).\n",
    "    \n",
    "    Interpretation:\n",
    "    \n",
    "    ğ‘…2=0: Model explains none of the variability.\n",
    "    \n",
    "    ğ‘…2=1: Model explains all the variability perfectly.\n",
    "    \n",
    "    Higher ğ‘…2 means the model fits the data better.\n",
    "    \n",
    "    Purpose:\n",
    "    It provides a goodness-of-fit measure, showing how much of the variation in Y can be explained by X. However, a very high RÂ² doesnâ€™t always mean a good model â€” it must also generalize well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "803ea9db-92fd-4d89-acae-29e8f3d0407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (Î²1): 0.6999999999999998\n",
      "Intercept (Î²0): 1.9000000000000004\n",
      "Predicted Values: [2.6 3.3 4.  4.7 5.4]\n"
     ]
    }
   ],
   "source": [
    "#9. Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Example dataset\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "y = np.array([3, 4, 2, 5, 6])\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print slope (coefficient) and intercept\n",
    "print(\"Slope (Î²1):\", model.coef_[0])\n",
    "print(\"Intercept (Î²0):\", model.intercept_)\n",
    "\n",
    "# Predict values\n",
    "y_pred = model.predict(X)\n",
    "print(\"Predicted Values:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0516f13-a40e-4877-bc66-23b0df201b7c",
   "metadata": {},
   "source": [
    " 10. How do you interpret the coefficients in a simple linear regression model?\n",
    "     \n",
    "    In Simple Linear Regression, the coefficients ğ›½0 (intercept) and ğ›½1(slope) describe the nature of the relationship between X and Y.\n",
    "\n",
    "    Intercept (Î²â‚€):\n",
    "    The expected value of Y when X = 0. It provides a baseline level of the dependent variable.\n",
    "    \n",
    "    Slope (Î²â‚):\n",
    "    Represents the change in Y for a one-unit increase in X.\n",
    "    \n",
    "    If Î²â‚ is positive â†’ Y increases with X (positive relationship).\n",
    "    \n",
    "    If Î²â‚ is negative â†’ Y decreases with X (negative relationship).\n",
    "    \n",
    "    For example, if \n",
    "    ğ‘Œ=50+2ğ‘‹ it means when X increases by 1 unit, Y increases by 2 units, starting from 50 when X = 0.\n",
    "    \n",
    "    The interpretation of coefficients helps in understanding the direction and strength of the effect of independent variables on the dependent variable, which is critical in business forecasting and data-driven decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbbdd9-b71d-4f56-8cb6-e1e006da31ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da13ce7-1d2f-4900-9008-5ea94320f847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
